p8105_hw5_hj2735
================
cindyjin
2025-11-12

### Problem 1

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(broom)
set.seed(1)
```

``` r
birthday_dup = function(n) {
  bdays = sample(1:365, size = n, replace = TRUE)
  # true if dup exists
  any(duplicated(bdays))
}
```

``` r
# Simulation: repeat 10000 times for group sizes 2–50
sim_results = 
  expand_grid(
    group_size = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    dup = map_lgl(group_size, birthday_dup)
  )
```

``` r
# Compute empirical probability for each group size
prob_df = 
  sim_results |> 
  group_by(group_size) |> 
  summarize(prob = mean(dup))
```

``` r
# Plot probability vs. group size
p = 
prob_df |> 
  ggplot(aes(x = group_size, y = prob)) +
  geom_line() +
  geom_point() +
  labs(
    x = "Group size (n)",
    y = "Probability of ≥1 shared birthday",
    title = "Birthday Problem Simulation"
  )

p
```

![](p8105_hw5_hj2735_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

``` r
ggsave("plots/birthday_prob_plot.png", p, width = 6, height = 4)
```

The probability of at least one shared birthday increases quickly with
group size. For example, at n = 10 the probability is 0.1158, and by n =
23 it reaches 0.5016, close to the well-known 0.5 threshold. By n = 50
the probability is 0.972, meaning shared birthdays are almost certain.

### Problem 2

``` r
# Function: simulate data from N(mu, sigma) and run one-sample t-test of H0: mu = 0
sim_ttest = function(mu, n = 30, sigma = 5) {
  
  # simulate n observations with true mean mu and sd sigma
  x = rnorm(n, mean = mu, sd = sigma)
  
  # run one-sample t-test against 0 and tidy the output
  t_out  = t.test(x, mu = 0)
  t_tidy = broom::tidy(t_out)
  
  # return estimated mean and p-value as a tibble
  tibble(
    mu_hat  = t_tidy$estimate,
    p_value = t_tidy$p.value
  )
}
```

``` r
sim_results = 
  expand_grid(
    mu_true = 0:6,        # true values of mu
    iter    = 1:5000      # 5000 datasets for each mu
  ) |> 
  mutate(
    # for each row, run sim_ttest using the corresponding mu_true
    out = map(mu_true, ~ sim_ttest(mu = .x))
  ) |> 
  unnest(out) |> 
  mutate(
    # indicator for rejecting H0 at alpha = 0.05
    reject = p_value < 0.05
  )
```

``` r
# proportion of rejections (power) for each true mu
power_df = 
  sim_results |> 
  group_by(mu_true) |> 
  summarize(power = mean(reject))

# power curve plot
power_plot = 
  power_df |> 
  ggplot(aes(x = mu_true, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean \u03bc",
    y = "Power (Pr(reject H0))",
    title = "Power of one-sample t-test (n = 30, \u03c3 = 5)"
  ) +
  theme_minimal()

power_plot
```

![](p8105_hw5_hj2735_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

``` r
ggsave("plots/power_curve.png", power_plot, width = 6, height = 4)
```

Power increases as the true mean μ gets farther from 0; small effects
have low power, and large effects are detected (rejected) much more
often.

``` r
# average mu_hat overall and in rejected samples only
mu_est_df = 
  sim_results |> 
  group_by(mu_true) |> 
  summarize(
    mean_hat_all     = mean(mu_hat),
    mean_hat_reject  = mean(mu_hat[reject])
  )

# reshape for plotting both lines together
mu_long = 
  mu_est_df |> 
  pivot_longer(
    mean_hat_all:mean_hat_reject,
    names_to = "type",
    values_to = "mean_hat"
  ) |> 
  mutate(
    type = recode(type,
                  mean_hat_all    = "All samples",
                  mean_hat_reject = "Rejected H0 only")
  )

mu_plot = 
  mu_long |> 
  ggplot(aes(x = mu_true, y = mean_hat, color = type)) +
  geom_line() +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    x = "True mean \u03bc",
    y = "Average estimate of \u03bc\u0302",
    color = "",
    title = "Average \u03bc\u0302 across all vs. rejected samples"
  ) +
  theme_minimal()

mu_plot
```

![](p8105_hw5_hj2735_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

``` r
ggsave("plots/mu_estimates.png", mu_plot, width = 6, height = 4)
```

The average estimate of μ̂ across all samples is close to the true value
of μ, e.g. when μ = 2, the overall mean μ̂ is 2.0117402, showing that the
estimator is approximately unbiased.

However, when examining only samples for which the null was rejected,
the average μ̂ is larger; for μ = 2, this conditional mean is 2.6200209.
Thus, conditioning on significance inflates the estimate of μ̂, creating
upward bias.

### Problem 3
